{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a Custom Classifier in Keras with Transfer Learning\n",
    "\n",
    "Steps shown below:\n",
    "\n",
    "- **Organize the data**: Download labeled images of cats and dogs from Kaggle. Then divide the images into training and validation folders.\n",
    "- **Set up the configuration**: Define a pipeline for reading data, including preprocessing the images (e.g. resizing) and batching multiple images together.\n",
    "- **Load and augment the data**: In the absence of a ton of training images, make small changes (augmentation) like rotation, zooming, etc to increase variation in training data.\n",
    "- **Define the model**: Take a pre-trained model, remove the last few layers, and append a new classifier layer. Freeze the weights of original layers (i.e. make them unmodifiable). Select an optimizer algorithm and a metric to track (like accuracy).\n",
    "- **Train and test**: Start training for a few iterations. Save the model to eventually load inside any application for predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Organize the data\n",
    "\n",
    "Before training, we need to store our [downloaded dataset](https://www.kaggle.com/c/dogs-vs-cats-redux-kernels-edition/download/train.zip) in the right folder structure. Remember to make the `data` directory where we will be performing the refactoring. We’ll divide the images into two sets – training and validation. Our directory structure will look something like this: \n",
    "\n",
    "```\n",
    "data\n",
    " |__train\n",
    " |    |__cat\n",
    " |    |__dog\n",
    " |__val\n",
    "      |__cat\n",
    "      |__dog\n",
    "```\n",
    "\n",
    "In Windows, the following lines of command can help achieve this directory structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Файлы распакованы в папку 'train'.\n",
      "Директории train и val успешно созданы.\n",
      "Файлы успешно распределены по папкам train и val.\n",
      "Путь к директории train: c:\\Users\\Валерия\\Documents\\GitHub\\Practical-Deep-Learning-Book\\code\\chapter-3\\data\\train\n",
      "Путь к директории val: c:\\Users\\Валерия\\Documents\\GitHub\\Practical-Deep-Learning-Book\\code\\chapter-3\\data\\val\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "# Define the relative path to the train.zip file\n",
    "zip_file_path = os.path.join('..', '..', 'Downloads', 'dogs-vs-cats-redux-kernels-edition', 'train.zip')\n",
    "\n",
    "# Define the directory for extraction\n",
    "data_dir = 'data'  # Main directory for extraction and work\n",
    "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(data_dir)  # Extract directly to 'data'\n",
    "\n",
    "# Check that the files were extracted to data/train\n",
    "train_files_dir = os.path.join(data_dir, 'train')\n",
    "if not os.path.exists(train_files_dir):\n",
    "    print(\"Error: The 'train' folder was not created.\")\n",
    "else:\n",
    "    print(\"Files extracted to the 'train' folder.\")\n",
    "\n",
    "# Create necessary directories\n",
    "os.makedirs(os.path.join(data_dir, 'train', 'cat'), exist_ok=True)\n",
    "os.makedirs(os.path.join(data_dir, 'train', 'dog'), exist_ok=True)\n",
    "os.makedirs(os.path.join(data_dir, 'val', 'cat'), exist_ok=True)\n",
    "os.makedirs(os.path.join(data_dir, 'val', 'dog'), exist_ok=True)\n",
    "\n",
    "print(\"Directories 'train' and 'val' successfully created.\")\n",
    "\n",
    "# Create a list of all files in the train directory (where the files were extracted)\n",
    "all_files = os.listdir(train_files_dir)\n",
    "\n",
    "# Filter files related to cats and dogs\n",
    "cat_files = [f for f in all_files if 'cat' in f and f.endswith('.jpg')]\n",
    "dog_files = [f for f in all_files if 'dog' in f and f.endswith('.jpg')]\n",
    "\n",
    "# Shuffle the lists randomly\n",
    "random.shuffle(cat_files)\n",
    "random.shuffle(dog_files)\n",
    "\n",
    "# Select 250 files for each category and move them to the train folders\n",
    "for f in cat_files[:250]:\n",
    "    shutil.move(os.path.join(train_files_dir, f), os.path.join(data_dir, 'train', 'cat', f))\n",
    "for f in dog_files[:250]:\n",
    "    shutil.move(os.path.join(train_files_dir, f), os.path.join(data_dir, 'train', 'dog', f))\n",
    "\n",
    "# Use the remaining files for the val (validation) folders\n",
    "for f in cat_files[250:500]:\n",
    "    shutil.move(os.path.join(train_files_dir, f), os.path.join(data_dir, 'val', 'cat', f))\n",
    "for f in dog_files[250:500]:\n",
    "    shutil.move(os.path.join(train_files_dir, f), os.path.join(data_dir, 'val', 'dog', f))\n",
    "\n",
    "print(\"Files successfully distributed into 'train' and 'val' folders.\")\n",
    "\n",
    "# Output absolute paths to the train and val directories\n",
    "train_dir_path = os.path.abspath(os.path.join(data_dir, 'train'))\n",
    "val_dir_path = os.path.abspath(os.path.join(data_dir, 'val'))\n",
    "\n",
    "print(f\"Path to the 'train' directory: {train_dir_path}\")\n",
    "print(f\"Path to the 'val' directory: {val_dir_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images in train/cat: 250\n",
      "Images in train/dog: 250\n",
      "Images in val/cat: 250\n",
      "Images in val/dog: 250\n"
     ]
    }
   ],
   "source": [
    "print(f\"Images in train/cat: {len(os.listdir(os.path.join(data_dir, 'train', 'cat')))}\")\n",
    "print(f\"Images in train/dog: {len(os.listdir(os.path.join(data_dir, 'train', 'dog')))}\")\n",
    "print(f\"Images in val/cat: {len(os.listdir(os.path.join(data_dir, 'val', 'cat')))}\")\n",
    "print(f\"Images in val/dog: {len(os.listdir(os.path.join(data_dir, 'val', 'dog')))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 25,000 files inside the data folder are prefixed with ‘cat’ and ‘dog’. Now, move the files into their respective directories. To keep our initial experiment short, we’ll pick 250 random files per class and place them in training and validation folders. You can increase/decrease this number anytime, to experiment with a trade-off between accuracy and speed. \n",
    "\n",
    "Classification accuracy on previously unseen images (in the validation folder) is a good proxy for how the classifier would perform in the real world. Ideally, the more training images, the better the learning will be. And, the more validation images, the better our classifier would perform in the real-world."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the configuration\n",
    "\n",
    "Let's start off with our Python program and begin with importing the necessary packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Flatten, Dense, Dropout, GlobalAveragePooling2D\n",
    "from keras.applications.mobilenet import MobileNet, preprocess_input\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's place all the configurations up-front. These can be modified in the future based on the dataset of your choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATA_DIR = os.path.join(data_dir, 'train')\n",
    "VALIDATION_DATA_DIR = os.path.join(data_dir, 'val')\n",
    "TRAIN_SAMPLES = 500\n",
    "VALIDATION_SAMPLES = 500\n",
    "NUM_CLASSES = 2\n",
    "IMG_WIDTH, IMG_HEIGHT = 224, 224\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and augment the data\n",
    "\n",
    "Colored images usually have 3 channels viz. red, green and blue, each with intensity value ranging from 0 to 255. To normalize it (i.e. bring the value between 0 to 1), we can rescale the image by dividing each pixel by 255. Or, we can use the default `preprocess_input` function in Keras which does the preprocessing for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input,\n",
    "                                   rotation_range=20,\n",
    "                                   width_shift_range=0.2,\n",
    "                                   height_shift_range=0.2,\n",
    "                                   zoom_range=0.2)\n",
    "val_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time to load the data from its directories and let the augmentation happen! \n",
    "\n",
    "A few key things to note:\n",
    "\n",
    "- Training one image at a time can be pretty inefficient, so we can batch them into groups. \n",
    "- To introduce more randomness during the training process, we’ll keep shuffling the images in each batch.\n",
    "- To bring reproducibility during multiple runs of the same program, we’ll give the random number generator a seed value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 500 images belonging to 2 classes.\n",
      "Found 500 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(TRAIN_DATA_DIR,\n",
    "                                                    target_size=(IMG_WIDTH,\n",
    "                                                                 IMG_HEIGHT),\n",
    "                                                    batch_size=BATCH_SIZE,\n",
    "                                                    shuffle=True,\n",
    "                                                    seed=12345,\n",
    "                                                    class_mode='categorical')\n",
    "validation_generator = val_datagen.flow_from_directory(\n",
    "    VALIDATION_DATA_DIR,\n",
    "    target_size=(IMG_WIDTH, IMG_HEIGHT),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the data is taken care of, we come to the most crucial component of our training process - the model. We will reuse a CNN previously trained on the ImageNet dataset, remove the ImageNet specific classifier in the last few layers, and replace it with our own classifier suited to our problem. For transfer learning, we’ll ‘freeze’ the weights of the original model, i.e. set those layers as unmodifiable, so only the layers of the new classifier (that we add) can be modified. To keep things fast, we’ll choose the MobileNet model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_maker():\n",
    "    base_model = MobileNet(include_top=False,\n",
    "                           input_shape=(IMG_WIDTH, IMG_HEIGHT, 3))\n",
    "    for layer in base_model.layers[:]:\n",
    "        layer.trainable = False\n",
    "    input = Input(shape=(IMG_WIDTH, IMG_HEIGHT, 3))\n",
    "    custom_model = base_model(input)\n",
    "    custom_model = GlobalAveragePooling2D()(custom_model)\n",
    "    custom_model = Dense(64, activation='relu')(custom_model)\n",
    "    custom_model = Dropout(0.5)(custom_model)\n",
    "    predictions = Dense(NUM_CLASSES, activation='softmax')(custom_model)\n",
    "    return Model(inputs=input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and test\n",
    "\n",
    "With both the data and model ready, all we have left to do is train the model. This is also known as fitting the model to the data. For training any model, we need to pick a loss function, an optimizer, initial learning rate and a metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Валерия\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\Валерия\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\normalization\\batch_normalization.py:979: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Валерия\\AppData\\Local\\Temp\\ipykernel_12208\\2507997108.py:5: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  model.fit_generator(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:From c:\\Users\\Валерия\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\Валерия\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "8/8 [==============================] - 38s 4s/step - loss: 0.9497 - acc: 0.6140 - val_loss: 0.1834 - val_acc: 0.9420\n",
      "Epoch 2/10\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.3160 - acc: 0.8720 - val_loss: 0.1116 - val_acc: 0.9640\n",
      "Epoch 3/10\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.2070 - acc: 0.9300 - val_loss: 0.0872 - val_acc: 0.9640\n",
      "Epoch 4/10\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.1605 - acc: 0.9380 - val_loss: 0.0749 - val_acc: 0.9720\n",
      "Epoch 5/10\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1261 - acc: 0.9540 - val_loss: 0.0677 - val_acc: 0.9740\n",
      "Epoch 6/10\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1308 - acc: 0.9560 - val_loss: 0.0648 - val_acc: 0.9740\n",
      "Epoch 7/10\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0978 - acc: 0.9620 - val_loss: 0.0625 - val_acc: 0.9720\n",
      "Epoch 8/10\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1238 - acc: 0.9620 - val_loss: 0.0599 - val_acc: 0.9760\n",
      "Epoch 9/10\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1168 - acc: 0.9620 - val_loss: 0.0646 - val_acc: 0.9720\n",
      "Epoch 10/10\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0895 - acc: 0.9700 - val_loss: 0.0638 - val_acc: 0.9720\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x230d4c10>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = model_maker()\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "              metrics=['acc'])\n",
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=math.ceil(float(TRAIN_SAMPLES) / BATCH_SIZE),\n",
    "    epochs=10,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=math.ceil(float(VALIDATION_SAMPLES) / BATCH_SIZE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By the 10th step, we observe about 97% validation accuracy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Валерия\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Prediction\n",
    "\n",
    "We can now load this model anytime and classify an image. The Keras function `load_model`, as the name suggests loads the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "model = load_model('model.h5')\n",
    "\n",
    "# Check the current working directory\n",
    "current_dir = os.getcwd()\n",
    "print(\"Current working directory:\", current_dir)\n",
    "\n",
    "# Check if the file model.h5 exists\n",
    "file_exists = os.path.isfile('model.h5')\n",
    "print(\"File 'model.h5' exists:\", file_exists)\n",
    "\n",
    "# Listing files in the current directory\n",
    "os.listdir(current_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let’s try loading our original sample images and see what results we get."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 638ms/step\n",
      "[[7.4766518e-04 9.9925226e-01]]\n",
      "{'cat': 0, 'dog': 1}\n"
     ]
    }
   ],
   "source": [
    "img_path = os.path.join('data', 'val', 'dog', 'dog.3714.jpg')\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "img_array = image.img_to_array(img)\n",
    "expanded_img_array = np.expand_dims(img_array, axis=0)\n",
    "preprocessed_img = expanded_img_array / 255.  # Preprocess the image\n",
    "prediction = model.predict(preprocessed_img)\n",
    "print(prediction)\n",
    "print(validation_generator.class_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time to analyze the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: I import packages one more time to avoid some errors on Windows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.mobilenet import MobileNet, preprocess_input\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "IMG_WIDTH, IMG_HEIGHT = 224, 224\n",
    "VALIDATION_DATA_DIR = os.path.join('data', 'val')\n",
    "VALIDATION_BATCH_SIZE = 64\n",
    "\n",
    "validation_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    VALIDATION_DATA_DIR,\n",
    "    target_size=(IMG_WIDTH, IMG_HEIGHT),\n",
    "    batch_size=VALIDATION_BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    class_mode='categorical')\n",
    "\n",
    "from keras.models import load_model\n",
    "from keras.utils import CustomObjectScope\n",
    "from keras.initializers import glorot_uniform\n",
    "\n",
    "with CustomObjectScope(\n",
    "    {'GlorotUniform': glorot_uniform()}):\n",
    "    model_path = os.path.join('data', 'model.h5')\n",
    "    \n",
    "# Experiments start here\n",
    "ground_truth = validation_generator.classes\n",
    "\n",
    "predictions = model.predict(validation_generator)\n",
    "\n",
    "# Create a dictionary of image index: true prediction\n",
    "prediction_table = {}\n",
    "for index, val in enumerate(predictions):\n",
    "    index_of_highest_probability = np.argmax(val)\n",
    "    value_of_highest_probability = val[index_of_highest_probability]\n",
    "    prediction_table[index] = [value_of_highest_probability,\n",
    "                               index_of_highest_probability,\n",
    "                               ground_truth[index]]\n",
    "\n",
    "assert len(predictions) == len(ground_truth) == len(prediction_table)\n",
    "\n",
    "def display(sorted_indices, message):\n",
    "    similar_image_paths = []\n",
    "    distances = []\n",
    "    for name, value in sorted_indices:\n",
    "        [probability, predicted_index, gt] = value\n",
    "        similar_image_paths.append(VALIDATION_DATA_DIR + fnames[name])\n",
    "        distances.append(probability)\n",
    "    plt.subplots(similar_image_paths, distances, message)\n",
    "\n",
    "# Predictions for the 'dog' class with the highest probability values\n",
    "indices = get_images_with_sorted_probabilities(prediction_table,\n",
    "                                               get_highest_probability=True,\n",
    "                                               label=1, number_of_items=10,\n",
    "                                               only_false_predictions=False)\n",
    "message = 'Images with the highest probability of containing dogs'\n",
    "display(indices[:10], message)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next checkpoint is to identify our best and worst predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions about the 'dog' class with the highest probability values\n",
    "indices = get_images_with_sorted_probabilities(prediction_table,\n",
    "get_highest_probability=True, label=1, number_of_items=10,\n",
    "only_false_predictions=False)\n",
    "message = 'Images with the highest probability of containing dogs'\n",
    "display(indices[:10], message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions about the 'dog' class with low probability values\n",
    "low_prob_dog_indices = get_images_with_sorted_probabilities(prediction_table,\n",
    "                                                            get_highest_probability=False, \n",
    "                                                            label=1,\n",
    "                                                            number_of_items=10, \n",
    "                                                            only_false_predictions=False)\n",
    "\n",
    "message = 'Images with the lowest probability of containing dogs'\n",
    "display(low_prob_dog_indices, message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erroneous predictions about the 'dog' class\n",
    "wrong_dog_indices = get_images_with_sorted_probabilities(prediction_table,\n",
    "                                                         get_highest_probability=True, \n",
    "                                                         label=1,\n",
    "                                                         number_of_items=10, \n",
    "                                                         only_false_predictions=True)\n",
    "\n",
    "message = 'Wrong predictions for images of dogs'\n",
    "display(wrong_dog_indices, message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions about the 'cat' class with the highest probability values\n",
    "high_prob_cat_indices = get_images_with_sorted_probabilities(prediction_table,\n",
    "                                                             get_highest_probability=True, \n",
    "                                                             label=0,\n",
    "                                                             number_of_items=10, \n",
    "                                                             only_false_predictions=False)\n",
    "\n",
    "message = 'Images with the highest probability of containing cats'\n",
    "display(high_prob_cat_indices, message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions about the 'cat' class with low probability values\n",
    "low_prob_cat_indices = get_images_with_sorted_probabilities(prediction_table,\n",
    "                                                            get_highest_probability=False, \n",
    "                                                            label=0,\n",
    "                                                            number_of_items=10, \n",
    "                                                            only_false_predictions=False)\n",
    "\n",
    "message = 'Images with the lowest probability of containing cats'\n",
    "display(low_prob_cat_indices, message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erroneous predictions about the 'cat' class\n",
    "wrong_cat_indices = get_images_with_sorted_probabilities(prediction_table,\n",
    "                                                         get_highest_probability=True, \n",
    "                                                         label=0,\n",
    "                                                         number_of_items=10, \n",
    "                                                         only_false_predictions=True)\n",
    "\n",
    "message = 'Wrong predictions for images of cats'\n",
    "display(wrong_cat_indices, message)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
